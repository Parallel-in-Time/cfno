{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc9cd70-4e93-4d62-b58f-d203a9929cf4",
   "metadata": {},
   "source": [
    "Ref Paper: [FOURIER NEURAL OPERATOR FOR PARAMETRIC PARTIAL DIFFERENTIAL EQUATIONS](https://arxiv.org/pdf/2010.08895) \n",
    "\n",
    "Ref Code: https://github.com/neuraloperator/neuraloperator/blob/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae673c-2bb3-4d4f-bbb4-587d9846661b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df066ca-8ddd-4fe4-ab55-542dfbb9a4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import functools\n",
    "import operator\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import math\n",
    "import copy\n",
    "import scipy\n",
    "import pickle\n",
    "from timeit import default_timer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.nn.functional \n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "import scipy.io\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a101887a-5707-4239-ba7a-0d0919f79636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "process_file = os.path.join(parent_dir,\"dedalus/data_processing.py\")\n",
    "sys.path.append(process_file)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83938954-18b4-4805-ab0d-73f24145c93c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7110ae0-df03-4bef-b90e-0ff012ff2c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "units = {\n",
    "    0: 'B',\n",
    "    1: 'KiB',\n",
    "    2: 'MiB',\n",
    "    3: 'GiB',\n",
    "    4: 'TiB'\n",
    "}\n",
    "\n",
    "\n",
    "def format_mem(x):\n",
    "    \"\"\"\n",
    "    Takes integer 'x' in bytes and returns a number in [0, 1024) and\n",
    "    the corresponding unit.\n",
    "\n",
    "    \"\"\"\n",
    "    if abs(x) < 1024:\n",
    "        return round(x, 2), 'B'\n",
    "\n",
    "    scale = math.log2(abs(x)) // 10\n",
    "    scaled_x = x / (1024 ** scale)\n",
    "    unit = units[scale]\n",
    "\n",
    "    if int(scaled_x) == scaled_x:\n",
    "        return int(scaled_x), unit\n",
    "\n",
    "    # rounding leads to 2 or fewer decimal places, as required\n",
    "    return round(scaled_x, 2), unit\n",
    "\n",
    "\n",
    "def format_tensor_size(x):\n",
    "    val, unit = format_mem(x)\n",
    "    return f'{val}{unit}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df94bd1c-3d9e-4a97-acea-932361b9c279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CudaMemoryDebugger():\n",
    "    \"\"\"\n",
    "    Helper to track changes in CUDA memory.\n",
    "\n",
    "    \"\"\"\n",
    "    DEVICE = 'cuda'\n",
    "    LAST_MEM = 0\n",
    "    ENABLED = True\n",
    "\n",
    "\n",
    "    def __init__(self, print_mem):\n",
    "        self.print_mem = print_mem\n",
    "        if not CudaMemoryDebugger.ENABLED:\n",
    "            return\n",
    "\n",
    "        cur_mem = torch.cuda.memory_allocated(CudaMemoryDebugger.DEVICE)\n",
    "        cur_mem_fmt, cur_mem_unit = format_mem(cur_mem)\n",
    "        print(f'cuda allocated (initial): {cur_mem_fmt:.2f}{cur_mem_unit}')\n",
    "        CudaMemoryDebugger.LAST_MEM = cur_mem\n",
    "\n",
    "    def print(self,id_str=None):\n",
    "        if not CudaMemoryDebugger.ENABLED:\n",
    "            return\n",
    "\n",
    "        desc = 'cuda allocated'\n",
    "\n",
    "        if id_str is not None:\n",
    "            desc += f' ({id_str})'\n",
    "\n",
    "        desc += ':'\n",
    "\n",
    "        cur_mem = torch.cuda.memory_allocated(CudaMemoryDebugger.DEVICE)\n",
    "        cur_mem_fmt, cur_mem_unit = format_mem(cur_mem)\n",
    "\n",
    "        diff = cur_mem - CudaMemoryDebugger.LAST_MEM\n",
    "        if self.print_mem:\n",
    "            if diff == 0:\n",
    "                print(f'{desc} {cur_mem_fmt:.2f}{cur_mem_unit} (no change)')\n",
    "\n",
    "            else:\n",
    "                diff_fmt, diff_unit = format_mem(diff)\n",
    "                print(f'{desc} {cur_mem_fmt:.2f}{cur_mem_unit}'\n",
    "                      f' ({diff_fmt:+}{diff_unit})')\n",
    "\n",
    "        CudaMemoryDebugger.LAST_MEM = cur_mem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912e1693-6e06-4e8f-8e69-afda4f676763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_process(file, xStep=1, zStep=1):\n",
    "    index = 0\n",
    "    inputs = []\n",
    "    filename = 'input_data.h5'\n",
    "    with h5py.File(filename, \"w\") as data:\n",
    "        iter_no = 1501\n",
    "        print( file, iter_no)\n",
    "        for t in range(iter_no):\n",
    "            vel_t,b_t, p_t, write_no, iteration, sim_time, time_step, wall_time = rbc_data(file, t, True, True)\n",
    "            inputs.append(np.concatenate((vel_t[0,::xStep,::zStep], vel_t[1,::xStep,::zStep], b_t, p_t), axis = 0))\n",
    "            index = index + 1\n",
    "        data['input'] = inputs\n",
    "    data.close()\n",
    "    return np.array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33333b8d-8954-4674-a75a-2931f74acd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rbc_data( filename, time, tasks=False, scales=False):\n",
    "    with h5py.File(filename, mode=\"r\") as f:\n",
    "        b_t = f[\"tasks/buoyancy\"][time]\n",
    "        vel_t = f[\"tasks/velocity\"][time]\n",
    "        p_t = f[\"tasks/pressure\"][time]\n",
    "        iteration = f[\"scales/iteration\"][time]\n",
    "        sim_time  = f[\"scales/sim_time\"][time]\n",
    "        time_step = f[\"scales/timestep\"][time]\n",
    "        wall_time = f[\"scales/wall_time\"][time]\n",
    "        write_no = f[\"scales/write_number\"][time]\n",
    "\n",
    "    f.close()\n",
    "    if tasks and scales:\n",
    "         return vel_t,b_t, p_t, write_no, iteration, sim_time, time_step, wall_time\n",
    "    elif tasks:\n",
    "         return vel_t,b_t, p_t\n",
    "    elif scales:\n",
    "         return write_no, iteration, sim_time, time_step, wall_time\n",
    "    else:\n",
    "         raise ValueError(\"Nothing to return!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e645f8-3672-4436-b67e-a9aa75aa131a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a1cea-9224-4b2a-a5ed-3de8c0e42197",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fourier Neural Operator for 2D spatial + 1D temporal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c1a805-f35f-4221-a29d-6b81f5f04b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels  \n",
    "        self.out_channels = out_channels\n",
    "        # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        # k_max = 12 in paper \n",
    "        self.modes1 = modes1                 \n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        \n",
    "        # R\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        # summation along in_channel \n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batchsize, width, size_x, size_y, T + padding]\n",
    "        batchsize = x.shape[0]\n",
    "        \n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1]) \n",
    "        # [batchsize, width, size_x, size_y, if (T + padding) is even ((T + padding)/2 +1) else (T + padding)/2 ]\n",
    "        \n",
    "        # Multiply relevant Fourier modes (Corners of R) --> R.FFT(x)\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)  # upper right\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2) # upper left\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3) # lower right\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4) # lower left\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1))) # x = [batchsize, width, size_x, size_y, T + padding]\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp1 = nn.Conv3d(in_channels, mid_channels, 1)\n",
    "        self.mlp2 = nn.Conv3d(mid_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input: [batchsize, in_channel=width, size_x, size_y, T + padding]\n",
    "        # weight: [mid_channel=width, in_channel=width, 1,1,1]\n",
    "        # output: [batchsize, out_channel=mid_channel, size_x, size_y, T + padding]\n",
    "        x = self.mlp1(x)\n",
    "        x = torch.nn.Functional.gelu(x)\n",
    "        # output: [batchsize, out_channel=mid_channel, size_x, size_y, T + padding]\n",
    "        x = self.mlp2(x)\n",
    "        # input: [batchsize, in_channel=mid_channel, size_x, size_y, T + padding]\n",
    "        # weight: [out_channel=width, mid_channel=width, 1, 1, 1]\n",
    "        # output: [batchsize, out_channel=width, size_x, size_y, T + padding]\n",
    "        return x\n",
    "\n",
    "class FNO3d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width):\n",
    "        super(FNO3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t).\n",
    "        It's a constant function in time, except for the last index.\n",
    "        input shape: (batchsize,  x=sizex, y=sizey, t=40, c=13)\n",
    "        output: the solution of the next 40 timesteps\n",
    "        output shape: (batchsize, x=sizex, y=sizey, t=40, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.padding = 6 # pad the domain if input is non-periodic\n",
    "        \n",
    "        # x = (batchsize,   x=sizex, y=sizey, t=40, c=13)\n",
    "        # input channel is 13: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n",
    "        self.p = nn.Linear(13, self.width)\n",
    "        self.conv0 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv1 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv2 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv3 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.mlp0 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp1 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp2 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp3 = MLP(self.width, self.width, self.width)\n",
    "        self.w0 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.q = MLP(self.width, 1, self.width * 4) # output channel is 1: u(x, y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device) # [batchsize,   size_x, size_y, T, c=T_in] ---> [batchsize,   size_x, size_y, T, c=3]\n",
    "        x = torch.cat((x, grid), dim=-1)        # [batchsize,   size_x, size_y, T, c=T_in+3]\n",
    "        x = self.p(x)                           \n",
    "        # input: [batchsize,   size_x, size_y, T, c=T_in+3], \n",
    "        # Weight: [width,T_in+3]\n",
    "        # Output: [batchsize,   size_x, size_y, T, c=width]\n",
    "        \n",
    "        x = x.permute(0, 5, 1, 2, 3,4)            # [batchsize,   size_x, size_y, T, c=width] --> [batchsize, width,   size_x, size_y, T]\n",
    "        x = torch.nn.functional.pad(x, [0,self.padding]) # pad the domain if input is non-periodic, padded along last dim of x\n",
    "        \n",
    "        # padding order:(padding_left,padding_right, \n",
    "        #                 padding_top,padding_bottom,\n",
    "        #                 padding_front,padding_back)\n",
    "                \n",
    "        # [batchsize, width,   size_x, size_y, T + padding]\n",
    "        \n",
    "        x1 = self.conv0(x) # SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        \n",
    "        # input: [batchsize, width,   size_x, size_y, T + padding]\n",
    "        # weight: torch.rand(in_channels=width, out_channels=width, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat)\n",
    "        # Output: [batchsize, out_channel=width,   size_x, size_y, T + padding]\n",
    "        \n",
    "        x1 = self.mlp0(x1) # MLP(self.width, self.width, self.width)\n",
    "        # input: [batchsize, in_channel=width,   size_x, size_y, T + padding]\n",
    "        # output: [batchsize, out_channel=width,    size_x, size_y, T + padding]\n",
    "        \n",
    "        x2 = self.w0(x)   # nn.Conv3d(self.width, self.width, 1)\n",
    "        # input: [batchsize, in_channel=width,   size_x, size_y, T + padding]\n",
    "        # weight: [out_channel=width, in_channel=width, 1, 1,1]\n",
    "        # output: [batchsize, out_channel=width,   size_x, size_y, T + padding]\n",
    "        \n",
    "        x = x1 + x2\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.mlp1(x1)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x1 = self.mlp2(x1)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x1 = self.mlp3(x1)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "        # output: [batchsize, out_channel=width,   size_x, size_y, T + padding]\n",
    "        \n",
    "        x = x[..., :-self.padding]\n",
    "        # output: [batchsize, out_channel=width,   size_x, size_y, T]\n",
    "        \n",
    "        x = self.q(x) # MLP(self.width, 1, self.width * 4) # output channel is 1: u(x, y)\n",
    "        \n",
    "        # input: [batchsize, in_channel=width,  size_x, size_y, T ]\n",
    "        # weight: [mid_channel=4*width, in_channel=width, 1,1,1]\n",
    "        # output: [batchsize, out_channel=mid_channel=4*width,   size_x, size_y, T ]\n",
    "        # x = self.mlp1(x)\n",
    "        # x = torch.nn.Functional.gelu(x)\n",
    "        # output: [batchsize, out_channel=mid_channel=4*width,  size_x, size_y, T]\n",
    "        # x = self.mlp2(x)\n",
    "        # input: [batchsize, in_channel=mid_channel=4*width,  size_x, size_y, T]\n",
    "        # weight: [out_channel=1, mid_channel=4*width, 1, 1, 1]\n",
    "        # output: [batchsize, out_channel=1,   size_x, size_y, T]\n",
    "        \n",
    "        x = x.permute(0, 2, 3,   5, 1) # pad the domain if input is non-periodic\n",
    "        # output: [batchsize,   size_x, size_y, T, out_channel=1]\n",
    "        return x\n",
    "\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "\n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1).to(device) # [batchsize,  size_x, size_y, size_z, 3]\n",
    "        \n",
    "    \n",
    "    def print_size(self):\n",
    "        properties = []\n",
    "\n",
    "        for param in self.parameters():\n",
    "            properties.append([list(param.size()+(2,) if param.is_complex() else param.size()), param.numel(), (param.data.element_size() * param.numel())/1000])\n",
    "            \n",
    "        elementFrame = pd.DataFrame(properties, columns = ['ParamSize', 'NParams', 'Memory(KB)'])\n",
    " \n",
    "        print(f'Total number of model parameters: {elementFrame[\"NParams\"].sum()} with (~{format_tensor_size(elementFrame[\"Memory(KB)\"].sum()*1000)})')\n",
    "        return elementFrame\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c88d6db-c963-4553-b4d5-043cbe7f92fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of model parameters: 3283881 with (~25.03MiB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParamSize</th>\n",
       "      <th>NParams</th>\n",
       "      <th>Memory(KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[20, 13]</td>\n",
       "      <td>260</td>\n",
       "      <td>1.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[20, 20, 8, 8, 8, 2]</td>\n",
       "      <td>204800</td>\n",
       "      <td>1638.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[20, 20, 1, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[80, 20, 1, 1, 1]</td>\n",
       "      <td>1600</td>\n",
       "      <td>6.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[80]</td>\n",
       "      <td>80</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[1, 80, 1, 1, 1]</td>\n",
       "      <td>80</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ParamSize  NParams  Memory(KB)\n",
       "0               [20, 13]      260       1.040\n",
       "1                   [20]       20       0.080\n",
       "2   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "3   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "4   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "5   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "6   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "7   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "8   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "9   [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "10  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "11  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "12  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "13  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "14  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "15  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "16  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "17  [20, 20, 8, 8, 8, 2]   204800    1638.400\n",
       "18     [20, 20, 1, 1, 1]      400       1.600\n",
       "19                  [20]       20       0.080\n",
       "20     [20, 20, 1, 1, 1]      400       1.600\n",
       "21                  [20]       20       0.080\n",
       "22     [20, 20, 1, 1, 1]      400       1.600\n",
       "23                  [20]       20       0.080\n",
       "24     [20, 20, 1, 1, 1]      400       1.600\n",
       "25                  [20]       20       0.080\n",
       "26     [20, 20, 1, 1, 1]      400       1.600\n",
       "27                  [20]       20       0.080\n",
       "28     [20, 20, 1, 1, 1]      400       1.600\n",
       "29                  [20]       20       0.080\n",
       "30     [20, 20, 1, 1, 1]      400       1.600\n",
       "31                  [20]       20       0.080\n",
       "32     [20, 20, 1, 1, 1]      400       1.600\n",
       "33                  [20]       20       0.080\n",
       "34     [20, 20, 1, 1, 1]      400       1.600\n",
       "35                  [20]       20       0.080\n",
       "36     [20, 20, 1, 1, 1]      400       1.600\n",
       "37                  [20]       20       0.080\n",
       "38     [20, 20, 1, 1, 1]      400       1.600\n",
       "39                  [20]       20       0.080\n",
       "40     [20, 20, 1, 1, 1]      400       1.600\n",
       "41                  [20]       20       0.080\n",
       "42     [80, 20, 1, 1, 1]     1600       6.400\n",
       "43                  [80]       80       0.320\n",
       "44      [1, 80, 1, 1, 1]       80       0.320\n",
       "45                   [1]        1       0.004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3d = FNO3d(8, 8, 8, 20)\n",
    "model3d.print_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cc79d-cb5a-4fa2-97fc-a1adff322bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fourier Neural Operator 2D Spatial + Recurrent in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6951d8c-e8d2-4cad-87ed-ea1967b2504e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (initial): 0.00B\n"
     ]
    }
   ],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1              #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :,  :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp1 = nn.Conv2d(in_channels, mid_channels, 1)\n",
    "        self.mlp2 = nn.Conv2d(mid_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp1(x)\n",
    "        x = nn.functional.gelu(x)\n",
    "        x = self.mlp2(x)\n",
    "        return x\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    memory = CudaMemoryDebugger(print_mem=True)\n",
    "    \n",
    "    def __init__(self, modes1, modes2, width):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "        input shape: (batchsize, x=sizex, y=sizey, c=12)\n",
    "        output: the solution of the next timestep\n",
    "        output shape: (batchsize, x=sizex, y=sizey, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.padding = 8 # pad the domain if input is non-periodic\n",
    "\n",
    "        self.p = nn.Linear(12, self.width) # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.mlp0 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp1 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp2 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp3 = MLP(self.width, self.width, self.width)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.norm = nn.InstanceNorm2d(self.width)\n",
    "        self.q = MLP(self.width, 1, self.width * 4) # output channel is 1: u(x, y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.p(x)\n",
    "        memory.print(\"after p(x)\")\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        x1 = self.norm(self.conv0(self.norm(x)))\n",
    "        x1 = self.mlp0(x1)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = nn.functional.gelu(x)\n",
    "        memory.print(\"after FNO1\")\n",
    "\n",
    "        x1 = self.norm(self.conv1(self.norm(x)))\n",
    "        x1 = self.mlp1(x1)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = nn.functional.gelu(x)\n",
    "        memory.print(\"after FNO2\")\n",
    "        \n",
    "        x1 = self.norm(self.conv2(self.norm(x)))\n",
    "        x1 = self.mlp2(x1)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = nn.functional.gelu(x)\n",
    "        memory.print(\"after FNO3\")\n",
    "        \n",
    "        x1 = self.norm(self.conv3(self.norm(x)))\n",
    "        x1 = self.mlp3(x1)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "        memory.print(\"after FNO4\")\n",
    "        \n",
    "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
    "        x = self.q(x)\n",
    "        memory.print(\"after q(x)\")\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        return x\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)\n",
    "    \n",
    "    def print_size(self):\n",
    "        properties = []\n",
    "\n",
    "        for param in self.parameters():\n",
    "            properties.append([list(param.size()+(2,) if param.is_complex() else param.size()), param.numel(), (param.data.element_size() * param.numel())/1000])\n",
    "            \n",
    "        elementFrame = pd.DataFrame(properties, columns = ['ParamSize', 'NParams', 'Memory(KB)'])\n",
    " \n",
    "        print(f'Total number of model parameters: {elementFrame[\"NParams\"].sum()} with (~{format_tensor_size(elementFrame[\"Memory(KB)\"].sum()*1000)})')\n",
    "        return elementFrame\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245b7454-a7d2-48e8-b484-6b269be1856a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of model parameters: 467861 with (~3.54MiB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParamSize</th>\n",
       "      <th>NParams</th>\n",
       "      <th>Memory(KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[20, 12]</td>\n",
       "      <td>240</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[20, 20, 12, 12, 2]</td>\n",
       "      <td>57600</td>\n",
       "      <td>460.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20, 20, 1, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[80, 20, 1, 1]</td>\n",
       "      <td>1600</td>\n",
       "      <td>6.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[80]</td>\n",
       "      <td>80</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[1, 80, 1, 1]</td>\n",
       "      <td>80</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ParamSize  NParams  Memory(KB)\n",
       "0              [20, 12]      240       0.960\n",
       "1                  [20]       20       0.080\n",
       "2   [20, 20, 12, 12, 2]    57600     460.800\n",
       "3   [20, 20, 12, 12, 2]    57600     460.800\n",
       "4   [20, 20, 12, 12, 2]    57600     460.800\n",
       "5   [20, 20, 12, 12, 2]    57600     460.800\n",
       "6   [20, 20, 12, 12, 2]    57600     460.800\n",
       "7   [20, 20, 12, 12, 2]    57600     460.800\n",
       "8   [20, 20, 12, 12, 2]    57600     460.800\n",
       "9   [20, 20, 12, 12, 2]    57600     460.800\n",
       "10       [20, 20, 1, 1]      400       1.600\n",
       "11                 [20]       20       0.080\n",
       "12       [20, 20, 1, 1]      400       1.600\n",
       "13                 [20]       20       0.080\n",
       "14       [20, 20, 1, 1]      400       1.600\n",
       "15                 [20]       20       0.080\n",
       "16       [20, 20, 1, 1]      400       1.600\n",
       "17                 [20]       20       0.080\n",
       "18       [20, 20, 1, 1]      400       1.600\n",
       "19                 [20]       20       0.080\n",
       "20       [20, 20, 1, 1]      400       1.600\n",
       "21                 [20]       20       0.080\n",
       "22       [20, 20, 1, 1]      400       1.600\n",
       "23                 [20]       20       0.080\n",
       "24       [20, 20, 1, 1]      400       1.600\n",
       "25                 [20]       20       0.080\n",
       "26       [20, 20, 1, 1]      400       1.600\n",
       "27                 [20]       20       0.080\n",
       "28       [20, 20, 1, 1]      400       1.600\n",
       "29                 [20]       20       0.080\n",
       "30       [20, 20, 1, 1]      400       1.600\n",
       "31                 [20]       20       0.080\n",
       "32       [20, 20, 1, 1]      400       1.600\n",
       "33                 [20]       20       0.080\n",
       "34       [80, 20, 1, 1]     1600       6.400\n",
       "35                 [80]       80       0.320\n",
       "36        [1, 80, 1, 1]       80       0.320\n",
       "37                  [1]        1       0.004"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2d= FNO2d(12,12,20)\n",
    "model2d.print_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6244ce-1696-4ff0-8bf9-e51630b02a5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b272749-a15c-469a-b2bb-501b0dfb0a64",
   "metadata": {},
   "source": [
    "Data generated using [rbc_simulation.py](dedalus/rbc_simulation.py)\n",
    "\n",
    "```\n",
    "srun python data_generation.py \\\n",
    "        --dir_name \"$DATA_DIR\" \\\n",
    "        --rayleigh 1e7 \\\n",
    "        --res_factor 1 \\\n",
    "        --seed 1000 \\\n",
    "        --sim_time 150 \n",
    "```\n",
    "\n",
    "`xStep, zStep = 1` \\\n",
    "Each row in an array is  `np.concatenate((vel_t[0,::xStep,::zStep], vel_t[1,::xStep,::zStep], b_t, p_t), axis = 0)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7a15bd9-4afe-4747-8677-0044efbb28c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = '/p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "761d895b-bf9e-4ebf-82a8-edd9b8579817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting RayleighNumber=10000000.0, Nx=256 and Nz=64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'dedalus.data_processing' from '/p/project1/cexalab/john2/NeuralOperators/neural_operators/dedalus/data_processing.py'>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dedalus import data_processing\n",
    "reload(data_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "eeac681f-1e5e-495e-ae84-86ef2d59250f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_arrange(root_dir, mode, samples):\n",
    "    data  = []\n",
    "    for i in tqdm(range(1, samples + 1)):\n",
    "        folder = f'{root_dir}_{mode}_{i}'\n",
    "        d = data_processing.OutputFiles(folder).data_process()\n",
    "        data.append(d)\n",
    "    s = np.array(data).shape\n",
    "    data = np.array(data).reshape(s[0], s[2], s[3], s[1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8e182737-1f77-45a7-8d2f-ff6aedd39132",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_1/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_1_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_2/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_2_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_3/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_3_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_4/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_4_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_5/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_5_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_6/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_6_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_7/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_7_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_8/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_8_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_9/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_9_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_10/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_10_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_11/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_11_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_12/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_12_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_13/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_13_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_14/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_14_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_15/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_15_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_16/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_16_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_17/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_17_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_18/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_18_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_19/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_19_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_20/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_20_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_21/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_21_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_22/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_22_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_23/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_23_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_24/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_24_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_25/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_25_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_26/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_26_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_27/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_27_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_28/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_28_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_29/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_29_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_30/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_30_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_31/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_31_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_32/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_32_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_33/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_33_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_34/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_34_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_35/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_35_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_36/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_36_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_37/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_37_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_38/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_38_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_39/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_39_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_40/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_40_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_41/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_41_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_42/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_42_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_43/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_43_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_44/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_44_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_45/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_45_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_46/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_46_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_47/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_47_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_48/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_48_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_49/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_49_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_50/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_50_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_51/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_51_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_52/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_52_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_53/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_53_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_54/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_54_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_55/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_55_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_56/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_56_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_57/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_57_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_58/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_58_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_59/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_59_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_60/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_60_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_61/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_61_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_62/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_62_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_63/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_63_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_64/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_64_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_65/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_65_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_66/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_66_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_67/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_67_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_68/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_68_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_69/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_69_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_70/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_70_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_71/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_71_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_72/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_72_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_73/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_73_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_74/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_74_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_75/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_75_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_76/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_76_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_77/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_77_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_78/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_78_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_79/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_79_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_80/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_80_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_81/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_81_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_82/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_82_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_83/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_83_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_84/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_84_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_85/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_85_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_86/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_86_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_87/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_87_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_88/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_88_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_89/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_89_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_90/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_90_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_91/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_91_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_92/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_92_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_93/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_93_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_94/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_94_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_95/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_95_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_96/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_96_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_97/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_97_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_98/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_98_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_99/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_99_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_100/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_train_100_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_1/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_1_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_2/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_2_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_3/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_3_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_4/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_4_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_5/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_5_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_6/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_6_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_7/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_7_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_8/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_8_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_9/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_9_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_10/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_10_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_11/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_11_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_12/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_12_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_13/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_13_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_14/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_14_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_15/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_15_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_16/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_16_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_17/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_17_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_18/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_18_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_19/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_19_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_20/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_20_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_21/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_21_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_22/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_22_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_23/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_23_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_24/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_24_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_25/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_25_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_26/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_26_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_27/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_27_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_28/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_28_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_29/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_29_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_30/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_30_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_31/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_31_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_32/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_32_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_33/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_33_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_34/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_34_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_35/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_35_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_36/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_36_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_37/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_37_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_38/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_38_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_39/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_39_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_40/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_40_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_41/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_41_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_42/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_42_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_43/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_43_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_44/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_44_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_45/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_45_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_46/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_46_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_47/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_47_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_48/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_48_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_49/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_49_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_50/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_test_50_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_1/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_1_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_2/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_2_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_3/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_3_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_4/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_4_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_5/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_5_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_6/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_6_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_7/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_7_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_8/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_8_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_9/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_9_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_10/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_10_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_11/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_11_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_12/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_12_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_13/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_13_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_14/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_14_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_15/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_15_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_16/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_16_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_17/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_17_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_18/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_18_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_19/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_19_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_20/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_20_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_21/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_21_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_22/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_22_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_23/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_23_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_24/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_24_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_25/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_25_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_26/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_26_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_27/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_27_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_28/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_28_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_29/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_29_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_30/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_30_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_31/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_31_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_32/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_32_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_33/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_33_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_34/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_34_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_35/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_35_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_36/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_36_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_37/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_37_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_38/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_38_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_39/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_39_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_40/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_40_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_41/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_41_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_42/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_42_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_43/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_43_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_44/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_44_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_45/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_45_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_46/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_46_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_47/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_47_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_48/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_48_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_49/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_49_s1.h5 1501\n",
      "0 /p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_50/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1_val_50_s1.h5 1501\n"
     ]
    }
   ],
   "source": [
    "train_data = data_arrange(root_dir, \"train\", 100)\n",
    "test_data = data_arrange(root_dir, \"test\", 50)\n",
    "val_data = data_arrange(root_dir, \"val\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ad2519b0-74f8-4529-b659-129bd0d7a193",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1024, 64, 1501) (50, 1024, 64, 1501) (50, 1024, 64, 1501)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "11d0edd6-a7e0-4cab-b062-6b29f9090898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = '/p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/processed_data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ca3b2278-014d-4d0b-933e-a8f29dd0a318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(filename, \"w\") as data:\n",
    "    data['train'] = train_data\n",
    "    data['test'] = test_data\n",
    "    data['val'] = val_data\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e0b11014-c655-4491-ac72-d444cc244d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1024, 64, 1501)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(filename, \"r\") as data:\n",
    "    print(data['train'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bddb94-cb29-481e-8720-e14ec1af7e4b",
   "metadata": {},
   "source": [
    "# 2D+Recurrent Time Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eadc960-d1df-4a32-846f-64835a76c973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ntrain = 100\n",
    "ntest = 50\n",
    "nval = 50\n",
    "\n",
    "modes = 12\n",
    "width = 20\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "iterations = epochs*(ntrain//batch_size)\n",
    "\n",
    "fno_path = Path(f'{os.getcwd()}/rbc_fno_2d_time_N{ntrain}_epoch{epochs}_m{modes}_w{width}')\n",
    "fno_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_train_err = Path(f'{fno_path}/results/train.txt')\n",
    "path_train_err.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_test_err = Path(f'{fno_path}/results/test.txt')\n",
    "path_test_err.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_image = Path(f'{fno_path}/image')\n",
    "path_image.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# gridx = 4*256\n",
    "# gridz = 64\n",
    "\n",
    "xStep = 1\n",
    "zStep = 1\n",
    "tStep = 1\n",
    "\n",
    "start_index = 500\n",
    "T_in = 10\n",
    "T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f23f6c02-4e0b-4e9f-ae46-b0e8c9e9949c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = '/p/project1/cexalab/john2/NeuralOperators/RayleighBernardConvection/processed_data/RBC2D_NX256_NZ64_TI0_TF150_Pr1_Ra1e7_dt0_1.h5'\n",
    "reader = h5py.File(data_path, mode=\"r\")\n",
    "train_a = torch.tensor(reader['train'][:ntrain, ::xStep, ::zStep, start_index: start_index+T_in],dtype=torch.float)\n",
    "train_u = torch.tensor(reader['train'][:ntrain, ::xStep, ::zStep, start_index+T_in:T+start_index+T_in], dtype=torch.float)\n",
    "\n",
    "test_a = torch.tensor(reader['test'][:ntest, ::xStep, ::zStep, start_index: start_index+T_in],dtype=torch.float)\n",
    "test_u = torch.tensor(reader['test'][:ntest, ::xStep, ::zStep, start_index+T_in:T+start_index+T_in],dtype=torch.float)\n",
    "\n",
    "val_a = torch.tensor(reader['val'][:nval, ::xStep, ::zStep, start_index: start_index+T_in],dtype=torch.float)\n",
    "val_u = torch.tensor(reader['val'][:nval, ::xStep, ::zStep, start_index+T_in:T+start_index+T_in],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f986458d-6666-48a7-96b5-609e47e9baba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1024, 64, 10]) torch.Size([50, 1024, 64, 10]) torch.Size([50, 1024, 64, 10])\n",
      "torch.Size([100, 1024, 64, 10]) torch.Size([50, 1024, 64, 10]) torch.Size([50, 1024, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(train_a.shape, val_a.shape, test_a.shape)\n",
    "print(train_u.shape, val_u.shape, test_u.shape)\n",
    "# assert (gridx == train_u.shape[-3])\n",
    "# assert (gridz == train_u.shape[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c84574c4-30e3-4118-a982-65dba2f01ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(val_a, val_u), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867d6cbf-2ae1-4387-a77a-c49772cdb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1024, 64, 10]) torch.Size([20, 1024, 64, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    print(xx.shape, yy.shape, xx.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe7f067-2bb7-471c-823e-f8e449df43e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed497f29-c64c-47b1-8a0b-c9dc041ba73b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (initial): 0.00B\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "memory = CudaMemoryDebugger(print_mem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "511aacfc-8f70-4f83-a145-e6419d523d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after intialization): 3.55MiB (+3.55MiB)\n"
     ]
    }
   ],
   "source": [
    "model2d = FNO2d(modes, modes, width).to(device)\n",
    "# print(model2d.print_size())\n",
    "memory.print(\"after intialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aca4def-a272-43bc-a3f0-a1d3e4f8dcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch loop:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after model.train()): 3.55MiB (no change)\n",
      "cuda allocated (after loading first batch): 103.55MiB (+100MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 281.68MiB (+178.12MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  10%|█         | 1/10 [00:00<00:03,  2.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 1.25GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 1.94GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 2.62GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 3.21GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 3.99GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  20%|██        | 2/10 [00:00<00:01,  4.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 3.96GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 4.94GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 5.62GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 6.31GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 6.89GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 7.68GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  30%|███       | 3/10 [00:00<00:01,  4.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 7.65GiB (-30.0MiB)\n",
      "cuda allocated (after FNO1): 8.63GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 9.31GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 10.00GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 10.58GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 11.37GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  40%|████      | 4/10 [00:00<00:01,  4.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 11.34GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 12.31GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 13.00GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 13.68GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 14.27GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 15.05GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  50%|█████     | 5/10 [00:01<00:01,  4.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 15.02GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 16.00GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 16.68GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 17.37GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 17.95GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 18.74GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 18.71GiB (-35.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  60%|██████    | 6/10 [00:01<00:00,  4.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 19.68GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 20.37GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 21.05GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 21.64GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 22.42GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  70%|███████   | 7/10 [00:01<00:00,  4.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 22.39GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 23.37GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 24.05GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 24.74GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 25.32GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 26.11GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 26.08GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 27.05GiB (+1000.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  80%|████████  | 8/10 [00:01<00:00,  4.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 27.74GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 28.42GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 29.01GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 29.79GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  90%|█████████ | 9/10 [00:02<00:00,  4.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 29.76GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 30.74GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 31.42GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 32.11GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 32.69GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 33.48GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop: 100%|██████████| 10/10 [00:02<00:00,  4.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 33.45GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 34.42GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 35.11GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 35.79GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 36.38GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 37.17GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after backwardpass): 235.47MiB (-36.94GiB)\n",
      "cuda allocated (after loading first batch): 285.47MiB (+50.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 405.47MiB (+120MiB)\n",
      "cuda allocated (after FNO1): 1.37GiB (+1000.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  10%|█         | 1/10 [00:00<00:01,  4.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 2.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 2.74GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 3.33GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 4.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 4.03GiB (-90.0MiB)\n",
      "cuda allocated (after FNO1): 5.00GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 5.69GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 6.37GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 6.96GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 7.75GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loop:  20%|██        | 2/10 [00:00<00:01,  5.03it/s]\u001b[A\n",
      "Train loop:  30%|███       | 3/10 [00:00<00:01,  4.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 7.72GiB (-30.0MiB)\n",
      "cuda allocated (after FNO1): 8.69GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 9.38GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 10.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 10.65GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 11.44GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  40%|████      | 4/10 [00:00<00:01,  4.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 11.40GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 12.38GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 13.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 13.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 14.34GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 15.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  50%|█████     | 5/10 [00:01<00:01,  4.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 15.09GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 16.06GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 16.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 17.43GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 18.02GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 18.81GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 18.77GiB (-35.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  60%|██████    | 6/10 [00:01<00:00,  4.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 19.75GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 20.43GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 21.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 21.71GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 22.49GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 22.46GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 23.44GiB (+1000.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  70%|███████   | 7/10 [00:01<00:00,  4.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 24.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 24.80GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 25.39GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 26.18GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 26.14GiB (-35.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  80%|████████  | 8/10 [00:01<00:00,  4.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 27.12GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 27.80GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 28.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 29.08GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 29.86GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  90%|█████████ | 9/10 [00:01<00:00,  4.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 29.83GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 30.81GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 31.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 32.17GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 32.76GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 33.55GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop: 100%|██████████| 10/10 [00:02<00:00,  4.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 33.51GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 34.49GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 35.17GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 35.86GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 36.45GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 37.23GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after backwardpass): 235.47MiB (-37.0GiB)\n",
      "cuda allocated (after loading first batch): 285.47MiB (+50.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Train loop:  10%|█         | 1/10 [00:00<00:01,  4.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 405.47MiB (+120MiB)\n",
      "cuda allocated (after FNO1): 1.37GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 2.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 2.74GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 3.33GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 4.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  20%|██        | 2/10 [00:00<00:02,  3.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 4.03GiB (-90.0MiB)\n",
      "cuda allocated (after FNO1): 5.00GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 5.69GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 6.37GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 6.96GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 7.75GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  30%|███       | 3/10 [00:00<00:01,  4.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 7.72GiB (-30.0MiB)\n",
      "cuda allocated (after FNO1): 8.69GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 9.38GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 10.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 10.65GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 11.44GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  40%|████      | 4/10 [00:00<00:01,  3.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 11.40GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 12.38GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 13.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 13.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 14.34GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 15.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  50%|█████     | 5/10 [00:01<00:01,  3.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 15.09GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 16.06GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 16.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 17.43GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 18.02GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 18.81GiB (+805.88MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  60%|██████    | 6/10 [00:01<00:00,  4.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 18.77GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 19.75GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 20.44GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 21.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 21.71GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 22.49GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 22.46GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 23.44GiB (+1000.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  70%|███████   | 7/10 [00:01<00:00,  4.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 24.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 24.80GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 25.39GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 26.18GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  80%|████████  | 8/10 [00:01<00:00,  3.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 26.14GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 27.12GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 27.81GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 28.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 29.08GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 29.86GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 29.83GiB (-35.87MiB)\n",
      "cuda allocated (after FNO1): 30.81GiB (+1000.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  90%|█████████ | 9/10 [00:02<00:00,  4.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 31.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 32.17GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 32.76GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 33.55GiB (+805.88MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 33.51GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 34.49GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 35.18GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 35.86GiB (+700.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop: 100%|██████████| 10/10 [00:02<00:00,  4.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO4): 36.45GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 37.23GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after backwardpass): 235.47MiB (-37.0GiB)\n",
      "cuda allocated (after loading first batch): 285.47MiB (+50.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 405.47MiB (+120MiB)\n",
      "cuda allocated (after FNO1): 1.37GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 2.06GiB (+700.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  10%|█         | 1/10 [00:00<00:02,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO3): 2.74GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 3.33GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 4.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 4.03GiB (-90.0MiB)\n",
      "cuda allocated (after FNO1): 5.00GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 5.69GiB (+700.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  20%|██        | 2/10 [00:00<00:01,  4.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO3): 6.37GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 6.96GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 7.75GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  30%|███       | 3/10 [00:00<00:01,  4.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 7.72GiB (-30.0MiB)\n",
      "cuda allocated (after FNO1): 8.69GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 9.38GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 10.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 10.65GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 11.44GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  40%|████      | 4/10 [00:00<00:01,  4.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 11.40GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 12.38GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 13.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 13.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 14.34GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 15.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 15.09GiB (-34.12MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  50%|█████     | 5/10 [00:01<00:01,  4.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 16.07GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 16.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 17.43GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 18.02GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 18.81GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 18.77GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 19.75GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 20.44GiB (+700.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  60%|██████    | 6/10 [00:01<00:00,  4.51it/s]\u001b[A\n",
      "Train loop:  70%|███████   | 7/10 [00:01<00:00,  4.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO3): 21.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 21.71GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 22.49GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 22.46GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 23.44GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 24.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 24.80GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 25.39GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 26.18GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  80%|████████  | 8/10 [00:01<00:00,  4.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 26.14GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 27.12GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 27.81GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 28.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 29.08GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 29.86GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 29.83GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 30.81GiB (+1000.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  90%|█████████ | 9/10 [00:01<00:00,  4.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 31.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 32.18GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 32.76GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 33.55GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop: 100%|██████████| 10/10 [00:02<00:00,  4.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 33.51GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 34.49GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 35.18GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 35.86GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 36.45GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 37.23GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after backwardpass): 235.47MiB (-37.0GiB)\n",
      "cuda allocated (after loading first batch): 285.47MiB (+50.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Train loop:  10%|█         | 1/10 [00:00<00:01,  5.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 405.47MiB (+120MiB)\n",
      "cuda allocated (after FNO1): 1.37GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 2.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 2.74GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 3.33GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 4.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  20%|██        | 2/10 [00:00<00:01,  4.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 4.03GiB (-90.0MiB)\n",
      "cuda allocated (after FNO1): 5.00GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 5.69GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 6.37GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 6.96GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 7.75GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 7.72GiB (-29.12MiB)\n",
      "cuda allocated (after FNO1): 8.70GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 9.38GiB (+700.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  30%|███       | 3/10 [00:00<00:01,  5.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO3): 10.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 10.65GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 11.44GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n",
      "cuda allocated (after p(x)): 11.40GiB (-35.87MiB)\n",
      "cuda allocated (after FNO1): 12.38GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 13.06GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 13.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 14.34GiB (+600.89MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after q(x)): 15.12GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  50%|█████     | 5/10 [00:01<00:01,  4.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 15.09GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 16.06GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 16.75GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 17.43GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 18.02GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 18.81GiB (+805.88MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  60%|██████    | 6/10 [00:01<00:00,  4.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 18.77GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 19.75GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 20.44GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 21.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 21.71GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 22.49GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  70%|███████   | 7/10 [00:01<00:00,  4.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 22.46GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 23.44GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 24.12GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 24.80GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 25.39GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 26.18GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  80%|████████  | 8/10 [00:01<00:00,  4.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 26.14GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 27.12GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 27.81GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 28.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 29.08GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 29.86GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop:  90%|█████████ | 9/10 [00:01<00:00,  4.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 29.83GiB (-35.87MiB)\n",
      "cuda allocated (after FNO1): 30.81GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 31.49GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 32.17GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 32.76GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 33.55GiB (+805.88MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loop: 100%|██████████| 10/10 [00:02<00:00,  4.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 33.51GiB (-35.0MiB)\n",
      "cuda allocated (after FNO1): 34.49GiB (+1000.89MiB)\n",
      "cuda allocated (after FNO2): 35.18GiB (+700.89MiB)\n",
      "cuda allocated (after FNO3): 35.86GiB (+700.89MiB)\n",
      "cuda allocated (after FNO4): 36.45GiB (+600.89MiB)\n",
      "cuda allocated (after q(x)): 37.23GiB (+805MiB)\n",
      "ouput: torch.Size([20, 1024, 64, 1]) pred: torch.Size([20, 1024, 64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after backwardpass): 235.47MiB (-37.0GiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validation loop:  10%|█         | 1/10 [00:00<00:01,  5.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 345.47MiB (+110.0MiB)\n",
      "cuda allocated (after FNO1): 545.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 545.47MiB (no change)\n",
      "cuda allocated (after FNO3): 545.47MiB (no change)\n",
      "cuda allocated (after FNO4): 545.47MiB (no change)\n",
      "cuda allocated (after q(x)): 450.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 295.47MiB (-155.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  20%|██        | 2/10 [00:00<00:01,  5.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 495.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 495.47MiB (no change)\n",
      "cuda allocated (after FNO3): 495.47MiB (no change)\n",
      "cuda allocated (after FNO4): 495.47MiB (no change)\n",
      "cuda allocated (after q(x)): 400.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 305.47MiB (-95MiB)\n",
      "cuda allocated (after FNO1): 505.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 505.47MiB (no change)\n",
      "cuda allocated (after FNO3): 505.47MiB (no change)\n",
      "cuda allocated (after FNO4): 505.47MiB (no change)\n",
      "cuda allocated (after q(x)): 410.47MiB (-95MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  30%|███       | 3/10 [00:00<00:01,  5.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 310.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 510.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 510.47MiB (no change)\n",
      "cuda allocated (after FNO3): 510.47MiB (no change)\n",
      "cuda allocated (after FNO4): 510.47MiB (no change)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  40%|████      | 4/10 [00:00<00:01,  5.01it/s]\u001b[A\n",
      "Validation loop:  50%|█████     | 5/10 [00:00<00:00,  5.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after q(x)): 415.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 315.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 515.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 515.47MiB (no change)\n",
      "cuda allocated (after FNO3): 515.47MiB (no change)\n",
      "cuda allocated (after FNO4): 515.47MiB (no change)\n",
      "cuda allocated (after q(x)): 420.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  60%|██████    | 6/10 [00:01<00:00,  4.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 320.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 520.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 520.47MiB (no change)\n",
      "cuda allocated (after FNO3): 520.47MiB (no change)\n",
      "cuda allocated (after FNO4): 520.47MiB (no change)\n",
      "cuda allocated (after q(x)): 425.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  70%|███████   | 7/10 [00:01<00:00,  4.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 325.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 525.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 525.47MiB (no change)\n",
      "cuda allocated (after FNO3): 525.47MiB (no change)\n",
      "cuda allocated (after FNO4): 525.47MiB (no change)\n",
      "cuda allocated (after q(x)): 430.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  80%|████████  | 8/10 [00:01<00:00,  4.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 330.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 530.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 530.47MiB (no change)\n",
      "cuda allocated (after FNO3): 530.47MiB (no change)\n",
      "cuda allocated (after FNO4): 530.47MiB (no change)\n",
      "cuda allocated (after q(x)): 435.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  90%|█████████ | 9/10 [00:01<00:00,  4.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 335.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 535.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 535.47MiB (no change)\n",
      "cuda allocated (after FNO3): 535.47MiB (no change)\n",
      "cuda allocated (after FNO4): 535.47MiB (no change)\n",
      "cuda allocated (after q(x)): 440.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 340.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 540.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 540.47MiB (no change)\n",
      "cuda allocated (after FNO3): 540.47MiB (no change)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO4): 540.47MiB (no change)\n",
      "cuda allocated (after q(x)): 445.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after val first batch): 235.47MiB (-210MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validation loop:  10%|█         | 1/10 [00:00<00:01,  5.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 345.47MiB (+110.0MiB)\n",
      "cuda allocated (after FNO1): 545.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 545.47MiB (no change)\n",
      "cuda allocated (after FNO3): 545.47MiB (no change)\n",
      "cuda allocated (after FNO4): 545.47MiB (no change)\n",
      "cuda allocated (after q(x)): 450.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  20%|██        | 2/10 [00:00<00:01,  4.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 295.47MiB (-155.0MiB)\n",
      "cuda allocated (after FNO1): 495.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 495.47MiB (no change)\n",
      "cuda allocated (after FNO3): 495.47MiB (no change)\n",
      "cuda allocated (after FNO4): 495.47MiB (no change)\n",
      "cuda allocated (after q(x)): 400.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  30%|███       | 3/10 [00:00<00:01,  4.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 305.47MiB (-95MiB)\n",
      "cuda allocated (after FNO1): 505.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 505.47MiB (no change)\n",
      "cuda allocated (after FNO3): 505.47MiB (no change)\n",
      "cuda allocated (after FNO4): 505.47MiB (no change)\n",
      "cuda allocated (after q(x)): 410.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  40%|████      | 4/10 [00:00<00:01,  4.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 310.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 510.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 510.47MiB (no change)\n",
      "cuda allocated (after FNO3): 510.47MiB (no change)\n",
      "cuda allocated (after FNO4): 510.47MiB (no change)\n",
      "cuda allocated (after q(x)): 415.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  50%|█████     | 5/10 [00:01<00:01,  4.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 315.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 515.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 515.47MiB (no change)\n",
      "cuda allocated (after FNO3): 515.47MiB (no change)\n",
      "cuda allocated (after FNO4): 515.47MiB (no change)\n",
      "cuda allocated (after q(x)): 420.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 320.47MiB (-100MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  60%|██████    | 6/10 [00:01<00:00,  4.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 520.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 520.47MiB (no change)\n",
      "cuda allocated (after FNO3): 520.47MiB (no change)\n",
      "cuda allocated (after FNO4): 520.47MiB (no change)\n",
      "cuda allocated (after q(x)): 425.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 325.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 525.47MiB (+200MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  70%|███████   | 7/10 [00:01<00:00,  4.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 525.47MiB (no change)\n",
      "cuda allocated (after FNO3): 525.47MiB (no change)\n",
      "cuda allocated (after FNO4): 525.47MiB (no change)\n",
      "cuda allocated (after q(x)): 430.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 330.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 530.47MiB (+200MiB)\n",
      "cuda allocated (after FNO2): 530.47MiB (no change)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  80%|████████  | 8/10 [00:01<00:00,  4.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO3): 530.47MiB (no change)\n",
      "cuda allocated (after FNO4): 530.47MiB (no change)\n",
      "cuda allocated (after q(x)): 435.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 335.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 535.47MiB (+200MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  90%|█████████ | 9/10 [00:01<00:00,  4.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 535.47MiB (no change)\n",
      "cuda allocated (after FNO3): 535.47MiB (no change)\n",
      "cuda allocated (after FNO4): 535.47MiB (no change)\n",
      "cuda allocated (after q(x)): 440.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 340.47MiB (-100MiB)\n",
      "cuda allocated (after FNO1): 540.47MiB (+200MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 540.47MiB (no change)\n",
      "cuda allocated (after FNO3): 540.47MiB (no change)\n",
      "cuda allocated (after FNO4): 540.47MiB (no change)\n",
      "cuda allocated (after q(x)): 445.47MiB (-95MiB)\n",
      "torch.Size([20, 1024, 64, 10])\n",
      "cuda allocated (after val first batch): 235.47MiB (-210MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation loop:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validation loop:  10%|█         | 1/10 [00:00<00:02,  3.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 240.47MiB (+5.0MiB)\n",
      "cuda allocated (after FNO1): 340.47MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 340.47MiB (no change)\n",
      "cuda allocated (after FNO3): 340.47MiB (no change)\n",
      "cuda allocated (after FNO4): 340.47MiB (no change)\n",
      "cuda allocated (after q(x)): 292.97MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 187.97MiB (-105.0MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  20%|██        | 2/10 [00:00<00:01,  4.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 287.97MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 287.97MiB (no change)\n",
      "cuda allocated (after FNO3): 287.97MiB (no change)\n",
      "cuda allocated (after FNO4): 287.97MiB (no change)\n",
      "cuda allocated (after q(x)): 240.47MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 192.97MiB (-47.5MiB)\n",
      "cuda allocated (after FNO1): 292.97MiB (+100MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  30%|███       | 3/10 [00:00<00:01,  4.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO2): 292.97MiB (no change)\n",
      "cuda allocated (after FNO3): 292.97MiB (no change)\n",
      "cuda allocated (after FNO4): 292.97MiB (no change)\n",
      "cuda allocated (after q(x)): 245.47MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 195.47MiB (-50MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  40%|████      | 4/10 [00:00<00:01,  4.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 295.47MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 295.47MiB (no change)\n",
      "cuda allocated (after FNO3): 295.47MiB (no change)\n",
      "cuda allocated (after FNO4): 295.47MiB (no change)\n",
      "cuda allocated (after q(x)): 247.97MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 197.97MiB (-50MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  50%|█████     | 5/10 [00:01<00:01,  4.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 297.97MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 297.97MiB (no change)\n",
      "cuda allocated (after FNO3): 297.97MiB (no change)\n",
      "cuda allocated (after FNO4): 297.97MiB (no change)\n",
      "cuda allocated (after q(x)): 250.47MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  60%|██████    | 6/10 [00:01<00:00,  4.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 200.47MiB (-50MiB)\n",
      "cuda allocated (after FNO1): 300.47MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 300.47MiB (no change)\n",
      "cuda allocated (after FNO3): 300.47MiB (no change)\n",
      "cuda allocated (after FNO4): 300.47MiB (no change)\n",
      "cuda allocated (after q(x)): 252.97MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  70%|███████   | 7/10 [00:01<00:00,  4.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 203.84MiB (-49.12MiB)\n",
      "cuda allocated (after FNO1): 303.84MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 303.84MiB (no change)\n",
      "cuda allocated (after FNO3): 303.84MiB (no change)\n",
      "cuda allocated (after FNO4): 303.84MiB (no change)\n",
      "cuda allocated (after q(x)): 256.34MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  80%|████████  | 8/10 [00:01<00:00,  4.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 205.47MiB (-50.88MiB)\n",
      "cuda allocated (after FNO1): 305.47MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 305.47MiB (no change)\n",
      "cuda allocated (after FNO3): 305.47MiB (no change)\n",
      "cuda allocated (after FNO4): 305.47MiB (no change)\n",
      "cuda allocated (after q(x)): 257.97MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop:  90%|█████████ | 9/10 [00:02<00:00,  4.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after p(x)): 208.84MiB (-49.12MiB)\n",
      "cuda allocated (after FNO1): 308.84MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 308.84MiB (no change)\n",
      "cuda allocated (after FNO3): 308.84MiB (no change)\n",
      "cuda allocated (after FNO4): 308.84MiB (no change)\n",
      "cuda allocated (after q(x)): 261.34MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n",
      "cuda allocated (after p(x)): 210.47MiB (-50.88MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loop: 100%|██████████| 10/10 [00:02<00:00,  4.39it/s]\u001b[A\n",
      " Epoch loop: 100%|██████████| 1/1 [00:39<00:00, 39.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after FNO1): 310.47MiB (+100MiB)\n",
      "cuda allocated (after FNO2): 310.47MiB (no change)\n",
      "cuda allocated (after FNO3): 310.47MiB (no change)\n",
      "cuda allocated (after FNO4): 310.47MiB (no change)\n",
      "cuda allocated (after q(x)): 262.97MiB (-47.5MiB)\n",
      "torch.Size([10, 1024, 64, 10])\n",
      "cuda allocated (after val first batch): 157.97MiB (-105MiB)\n",
      "0 39.14516788022593 0.9505900421142577 0.950590991973877 1.1083130798339844 1.1083130645751953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "optimizer = torch.optim.Adam(model2d.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "for ep in tqdm(range(1), desc=\" Epoch loop\"):#epochs\n",
    "    model2d.train()\n",
    "    memory.print(\"after model.train()\")\n",
    "    t1 = default_timer()\n",
    "    train_l2_step = 0\n",
    "    train_l2_full = 0\n",
    "    for xx, yy in train_loader:\n",
    "        loss = 0\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "        memory.print(\"after loading first batch\")\n",
    "\n",
    "        for t in tqdm(range(0,T, tStep), desc=\"Train loop\"):\n",
    "            y = yy[..., t:t + tStep]\n",
    "            im = model2d(xx)\n",
    "            print(\"ouput:\",y.shape,\"pred:\", im.shape)\n",
    "            loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
    "\n",
    "            if t == 0:\n",
    "                pred = im\n",
    "            else:\n",
    "                pred = torch.cat((pred, im), -1)\n",
    "\n",
    "            xx = torch.cat((xx[..., tStep:], im), dim=-1)\n",
    "\n",
    "        train_l2_step += loss.item()\n",
    "        l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n",
    "        train_l2_full += l2_full.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        memory.print(\"after backwardpass\")\n",
    "\n",
    "    val_l2_step = 0\n",
    "    val_l2_full = 0\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in val_loader:\n",
    "            loss = 0\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            for t in tqdm(range(0, T, tStep), desc=\"Validation loop\"):\n",
    "                y = yy[..., t:t + tStep]\n",
    "                im = model2d(xx)\n",
    "                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
    "\n",
    "                if t == 0:\n",
    "                    pred = im\n",
    "                else:\n",
    "                    pred = torch.cat((pred, im), -1)\n",
    "\n",
    "                xx = torch.cat((xx[..., tStep:], im), dim=-1)\n",
    "                print(xx.shape)\n",
    "\n",
    "            val_l2_step += loss.item()\n",
    "            val_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n",
    "            memory.print(\"after val first batch\")\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2 - t1, train_l2_step / ntrain / (T / tStep), train_l2_full / ntrain, val_l2_step / nval / (T / tStep),\n",
    "          val_l2_full / nval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9922fe69-f7b3-4924-be2c-55c52cf02885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda allocated (after one epoch): 157.97MiB (no change)\n"
     ]
    }
   ],
   "source": [
    "memory.print(\"after one epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1d9b1-010b-4b77-aac0-4d0d3570fe25",
   "metadata": {},
   "source": [
    "# Inference Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac586aa-beef-440e-9716-0a2c0649a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row = 1\n",
    "col = 5\n",
    "i = np.arange(0,64,1)\n",
    "t = t_start + 1\n",
    "write_no, iteration, sim_time, time_step, wall_time = rbc_scales('multi', file1, 0, t)\n",
    "print(k,t,write_no, iteration, sim_time, time_step, wall_time)\n",
    "print('-------------------------------')\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "ax1 = fig.add_subplot(row, col, 1)\n",
    "ax1.set_title('Input u(x,z)_{t+1} vs model_{t}')\n",
    "ax1.plot(x1[:,i,0],color='b',label=\"u_x\")\n",
    "ax1.plot(x1[:,i,1],color='b',label=\"u_z\")\n",
    "ax1.plot(z1[:,i,0],'.',color='g',label=\"u_x\")\n",
    "ax1.plot(z1[:,i,1],'.',color='g',label=\"u_z\")\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = fig.add_subplot(row, col, 2)\n",
    "ax2.set_title(f'Velocity x-component at t={np.round(sim_time,2)}')\n",
    "ax2.plot(y[:,i,0],color='b',label=\"Dedalus\")\n",
    "ax2.plot(z[:,i,0],'.',color='g',label=\"FNO\")\n",
    "ax2.grid()\n",
    "\n",
    "\n",
    "ax3 = fig.add_subplot(row, col, 3)\n",
    "ax3.set_title(f'Velocity z-component at t={np.round(sim_time,2)}')\n",
    "ax3.plot(y[:,i,1],color='b',label=\"Dedalus\")\n",
    "ax3.plot(z[:,i,1],'.',color='g',label=\"FNO\")\n",
    "ax3.grid()\n",
    "\n",
    "ax4 = fig.add_subplot(row, col, 4)\n",
    "ax4.set_title(f'Buoyancy at t={np.round(sim_time,2)}')\n",
    "ax4.plot(y[:,i,2],color='b',label=\"Dedalus\")\n",
    "ax4.plot(z[:,i,2],'.',color='g',label=\"FNO\")\n",
    "ax4.grid()\n",
    "\n",
    "ax5 = fig.add_subplot(row, col, 5)\n",
    "ax5.set_title(f'Pressure at t={np.round(sim_time,2)}')\n",
    "ax5.plot(y[:,i,3],color='b', label=\"Dedalus\")\n",
    "ax5.plot(z[:,i,3],'.',color='g', label=\"FNO\")\n",
    "ax5.grid()\n",
    "\n",
    "\n",
    "fig.suptitle(f'RBC-2D with {sx}'+r'$\\times$'+f'{sz} grid and $Ra=10^4, Pr=0.8$ with inputs at $t={np.round(sim_time1,2)}$',x=0.6, y =0.98)#\\n *(FNO=green[\".\"],Dedalus=[\"-\"])')\n",
    "ded_patch = Line2D([0], [0], label='Dedalus', color='b')\n",
    "fno_patch = Line2D([0], [0], label='FNO',marker='.', color='g')\n",
    "fig.legend(handles=[ded_patch, fno_patch], loc=\"upper right\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "no_jureca_kernel",
   "language": "python",
   "name": "no_jureca_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
